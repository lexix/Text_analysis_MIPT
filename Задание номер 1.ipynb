{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание номер 1. \n",
    "Гончаров Алексей Владимирович, 274 группа ФУПМ, 5 курс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункты 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('SMSSpamCollection') as f:\n",
    "    data_ = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве разделителей между ответом и объектом используют '\\t'. В качестве разделителей между строками используют '\\n'. Подготовим список текстов и ответов в переменных text и y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([x.replace('\\n','').split('\\t') for x in data_],columns=['answer','text'])\n",
    "text = data.text\n",
    "answer = data.answer\n",
    "y = answer.replace(to_replace = ['ham','spam'],value = [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt = CountVectorizer()\n",
    "mtrx = cnt.fit_transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93334852685794145"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "clf = LogisticRegression()\n",
    "cross_val_score(clf,mtrx,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_msg = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use your phone now! Subscribe6GB\",\n",
    "          \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "            \"Have you visited the last lecture on physics?\",\n",
    "            \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "            \"Only 99$\"]\n",
    "new_mtrx = cnt.transform(new_msg)\n",
    "clf.fit(mtrx,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(new_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print ' '.join([str(x) for x in pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt22 = CountVectorizer(ngram_range=(2,2))\n",
    "mtrx22 = cnt22.fit_transform(text)\n",
    "\n",
    "cnt33 = CountVectorizer(ngram_range=(3,3))\n",
    "mtrx33 = cnt33.fit_transform(text)\n",
    "\n",
    "cnt13 = CountVectorizer(ngram_range=(1,3))\n",
    "mtrx13 = cnt13.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range=(2,2):  0.82\n",
      "ngram_range=(3,3):  0.73\n",
      "ngram_range=(1,3):  0.93\n"
     ]
    }
   ],
   "source": [
    "print 'ngram_range=(2,2): ',round(cross_val_score(clf,mtrx22,y,cv=10, scoring = 'f1').mean(),2)\n",
    "print 'ngram_range=(3,3): ',round(cross_val_score(clf,mtrx33,y,cv=10, scoring = 'f1').mean(),2)\n",
    "print 'ngram_range=(1,3): ',round(cross_val_score(clf,mtrx13,y,cv=10, scoring = 'f1').mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 0.73 0.93\n"
     ]
    }
   ],
   "source": [
    "print round(cross_val_score(clf,mtrx22,y,cv=10, scoring = 'f1').mean(),2),round(cross_val_score(clf,mtrx33,y,cv=10, scoring = 'f1').mean(),2),round(cross_val_score(clf,mtrx13,y,cv=10, scoring = 'f1').mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range=(1,1):  0.93\n",
      "ngram_range=(2,2):  0.82\n",
      "ngram_range=(3,3):  0.73\n",
      "ngram_range=(1,3):  0.93\n"
     ]
    }
   ],
   "source": [
    "print 'ngram_range=(1,1): ', round(cross_val_score(clf,mtrx,y,cv=10, scoring = 'f1').mean(),2)\n",
    "print 'ngram_range=(2,2): ',round(cross_val_score(clf,mtrx22,y,cv=10, scoring = 'f1').mean(),2)\n",
    "print 'ngram_range=(3,3): ',round(cross_val_score(clf,mtrx33,y,cv=10, scoring = 'f1').mean(),2)\n",
    "print 'ngram_range=(1,3): ',round(cross_val_score(clf,mtrx13,y,cv=10, scoring = 'f1').mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93 0.82 0.73 0.93\n"
     ]
    }
   ],
   "source": [
    "print round(cross_val_score(clf,mtrx,y,cv=10, scoring = 'f1').mean(),2),round(cross_val_score(clf,mtrx22,y,cv=10, scoring = 'f1').mean(),2),round(cross_val_score(clf,mtrx33,y,cv=10, scoring = 'f1').mean(),2),round(cross_val_score(clf,mtrx13,y,cv=10, scoring = 'f1').mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtrx_tf = tf.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85285995541724557"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "cross_val_score(clf,mtrx_tf,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка текста: \n",
    "    - приведение к нижнему регистру\n",
    "    - удалние стоп-слов\n",
    "    - лемматизация\n",
    "    - стэмминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_text = [(' '.join([ps.stem(lemmatizer.lemmatize(lemmatizer.lemmatize(x,pos='a'))).lower() for x in word_tokenize(y.decode('utf8')) if x not in stopwords.words(\"english\")])) for y in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример обработки текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "i 'm gon na home soon n't want talk stuff anymor tonight , k ? i 've cri enough today .\n"
     ]
    }
   ],
   "source": [
    "print text[10]\n",
    "print new_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_mtrx_tf = tf.fit_transform(new_text)\n",
    "new_mtrx = cnt.fit_transform(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = answer.replace(to_replace = ['ham','spam'],value = [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат классификации tf_idf хуже, чем на обычной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844045278146211"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "cross_val_score(clf,new_mtrx_tf,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'penalty':('l1', 'l2'), \n",
    "              'C':[1, 10, 100, 1000, 10000, 100000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ('l1', 'l2'), 'C': [1, 10, 100, 1000, 10000, 100000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_srch = GridSearchCV(clf, parameters)\n",
    "gr_srch.fit(new_mtrx,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_srch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94564252386085546"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=100,penalty='l2')\n",
    "cross_val_score(clf,new_mtrx,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат классификации при CountVectorizer лучше, чем при обычной предобработке, на один-два процента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_text2 = [(' '.join([x.lower() for x in word_tokenize(y.decode('utf8')) if x not in stopwords.words(\"english\")])) for y in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С удалением стоп-слов с приведением к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94400491578463319"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mtrx2 = cnt.fit_transform(new_text2)\n",
    "y = answer.replace(to_replace = ['ham','spam'],value = [0,1])\n",
    "clf = LogisticRegression(C=100,penalty='l2')\n",
    "cross_val_score(clf,new_mtrx2,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без удаления стоп-слов с приведением к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93971646290740873"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text3 = [(' '.join([x.lower() for x in word_tokenize(y.decode('utf8')) ])) for y in text]\n",
    "new_mtrx3 = cnt.fit_transform(new_text3)\n",
    "y = answer.replace(to_replace = ['ham','spam'],value = [0,1])\n",
    "clf = LogisticRegression(C=100,penalty='l2')\n",
    "cross_val_score(clf,new_mtrx3,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С удалением стоп-слов с приведением к нижнему регистру и стэмминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_text4 = [(' '.join([ps.stem(x).lower() for x in word_tokenize(y.decode('utf8')) if x not in stopwords.words(\"english\")])) for y in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94640305829045457"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mtrx4 = cnt.fit_transform(new_text4)\n",
    "y = answer.replace(to_replace = ['ham','spam'],value = [0,1])\n",
    "clf = LogisticRegression(C=100,penalty='l2')\n",
    "cross_val_score(clf,new_mtrx4,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_text5 = [(' '.join([lemmatizer.lemmatize(x).lower() for x in word_tokenize(y.decode('utf8')) if x not in stopwords.words(\"english\")])) for y in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С удалением стоп-слов с приведением к нижнему регистру и лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94326873939362399"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mtrx5 = cnt.fit_transform(new_text5)\n",
    "y = answer.replace(to_replace = ['ham','spam'],value = [0,1])\n",
    "clf = LogisticRegression(C=100,penalty='l2')\n",
    "cross_val_score(clf,new_mtrx5,y,cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
